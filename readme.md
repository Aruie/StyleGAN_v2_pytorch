# StyleGAN V2





# 세부 아키텍쳐


- Generator 
  - LeakyRELU 0.2 사용
  - 모든 레이어에 같은 학습률 적용
  - Const Layer 의 경우 하나로 통일
  - 모든가중치는 표준정규분포에서 추출
  - 모든 Bias 와 Noise Scaling Factor 는 0으로 초기화 ( 1로 초기화하는 Y_s 와 관련된 Bias를 제외하고 )

- Mapping Network
  - 모든 입력과 출력의 차원은 512
  - 맵핑 네트워크가 깊을때 높은 학습률 적용시 잘학습이안되어 학습율은 1/00 으로감소


- Initialization
  - 학습전 10000개의 랜덤 z에 대한 w에 대해 유클리디안 거리를 이용해 분산을 측정
  - 총 1000번의 이터레이션 사용
  - 이값으로 w를 초기화 하고 노이즈는 표준정규분포 사용
  - 초기화는 처음 50회동안 0에서 0.1까지 선형적으로 상승 후 250회에 걸친 코사인감쇠를 사용해 0으로 하강
  - 처음 3/4 부분에선 가우시안 노이즈를 추가
    - 표준편차가 : 0.05 * sigma(w) * t^2 
    - t는 750회동안 1에서 0으로감
    - 
